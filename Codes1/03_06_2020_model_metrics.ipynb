{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr=pd.read_csv(r\"C:\\ksr\\data science\\DS_batch1\\datasets\\HR_comma_sep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
       "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
       "       'promotion_last_5years', 'Departments ', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.rename(columns=lambda x:x.strip(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
       "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
       "       'promotion_last_5years', 'Departments', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years Departments  \\\n",
       "0                   3              0     1                      0       sales   \n",
       "1                   6              0     1                      0       sales   \n",
       "2                   4              0     1                      0       sales   \n",
       "3                   5              0     1                      0       sales   \n",
       "4                   3              0     1                      0       sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr[\"number_project\"]=hr[\"number_project\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation number_project  average_montly_hours  \\\n",
       "0                0.38             0.53              2                   157   \n",
       "1                0.80             0.86              5                   262   \n",
       "2                0.11             0.88              7                   272   \n",
       "3                0.72             0.87              5                   223   \n",
       "4                0.37             0.52              2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years Departments  \\\n",
       "0                   3              0     1                      0       sales   \n",
       "1                   6              0     1                      0       sales   \n",
       "2                   4              0     1                      0       sales   \n",
       "3                   5              0     1                      0       sales   \n",
       "4                   3              0     1                      0       sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level        float64\n",
       "last_evaluation           float64\n",
       "number_project           category\n",
       "average_montly_hours        int64\n",
       "time_spend_company          int64\n",
       "Work_accident               int64\n",
       "left                        int64\n",
       "promotion_last_5years       int64\n",
       "Departments                object\n",
       "salary                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr[\"time_spend_company\"]=hr[\"time_spend_company\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr1=pd.get_dummies(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>number_project_2</th>\n",
       "      <th>number_project_3</th>\n",
       "      <th>number_project_4</th>\n",
       "      <th>number_project_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Departments_hr</th>\n",
       "      <th>Departments_management</th>\n",
       "      <th>Departments_marketing</th>\n",
       "      <th>Departments_product_mng</th>\n",
       "      <th>Departments_sales</th>\n",
       "      <th>Departments_support</th>\n",
       "      <th>Departments_technical</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  average_montly_hours  Work_accident  \\\n",
       "0                0.38             0.53                   157              0   \n",
       "1                0.80             0.86                   262              0   \n",
       "2                0.11             0.88                   272              0   \n",
       "3                0.72             0.87                   223              0   \n",
       "4                0.37             0.52                   159              0   \n",
       "\n",
       "   left  promotion_last_5years  number_project_2  number_project_3  \\\n",
       "0     1                      0                 1                 0   \n",
       "1     1                      0                 0                 0   \n",
       "2     1                      0                 0                 0   \n",
       "3     1                      0                 0                 0   \n",
       "4     1                      0                 1                 0   \n",
       "\n",
       "   number_project_4  number_project_5  ...  Departments_hr  \\\n",
       "0                 0                 0  ...               0   \n",
       "1                 0                 1  ...               0   \n",
       "2                 0                 0  ...               0   \n",
       "3                 0                 1  ...               0   \n",
       "4                 0                 0  ...               0   \n",
       "\n",
       "   Departments_management  Departments_marketing  Departments_product_mng  \\\n",
       "0                       0                      0                        0   \n",
       "1                       0                      0                        0   \n",
       "2                       0                      0                        0   \n",
       "3                       0                      0                        0   \n",
       "4                       0                      0                        0   \n",
       "\n",
       "   Departments_sales  Departments_support  Departments_technical  salary_high  \\\n",
       "0                  1                    0                      0            0   \n",
       "1                  1                    0                      0            0   \n",
       "2                  1                    0                      0            0   \n",
       "3                  1                    0                      0            0   \n",
       "4                  1                    0                      0            0   \n",
       "\n",
       "   salary_low  salary_medium  \n",
       "0           1              0  \n",
       "1           0              1  \n",
       "2           0              1  \n",
       "3           1              0  \n",
       "4           1              0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10499, 33) (4500, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "train,test=train_test_split(hr1,test_size=0.3,random_state=0)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.drop([\"left\"],axis=1)\n",
    "y_train=train[\"left\"]\n",
    "x_test=test.drop([\"left\"],axis=1)\n",
    "y_test=test[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression(solver=\"lbfgs\")\n",
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin)\n",
      " |  LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      " |  that regularization is applied by default**. It can handle both dense\n",
      " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      " |  floats for optimal performance; any other input format will be converted\n",
      " |  (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      " |  'saga' solver.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1', 'l2', 'elasticnet' or 'none', optional (default='l2')\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is\n",
      " |      only supported by the 'saga' solver. If 'none' (not supported by the\n",
      " |      liblinear solver), no regularization is applied.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, optional (default=False)\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-4)\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, optional (default=1.0)\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, optional (default=True)\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, optional (default=1)\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              optional (default='lbfgs')\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty\n",
      " |      - 'liblinear' and 'saga' also handle L1 penalty\n",
      " |      - 'saga' also supports 'elasticnet' penalty\n",
      " |      - 'liblinear' does not support setting ``penalty='none'``\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, optional (default=100)\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : {'ovr', 'multinomial', 'auto'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  l1_ratio : float or None, optional (default=None)\n",
      " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      " |      used if ``penalty='elasticnet'`. Setting ``l1_ratio=0`` is equivalent\n",
      " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : array, shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :])\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lg1=LogisticRegressionCV()\n",
    "lg1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegressionCV in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegressionCV(LogisticRegression, sklearn.base.BaseEstimator, sklearn.linear_model._base.LinearClassifierMixin)\n",
      " |  LogisticRegressionCV(Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=100, class_weight=None, n_jobs=None, verbose=0, refit=True, intercept_scaling=1.0, multi_class='auto', random_state=None, l1_ratios=None)\n",
      " |  \n",
      " |  Logistic Regression CV (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  See glossary entry for :term:`cross-validation estimator`.\n",
      " |  \n",
      " |  This class implements logistic regression using liblinear, newton-cg, sag\n",
      " |  of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2\n",
      " |  regularization with primal formulation. The liblinear solver supports both\n",
      " |  L1 and L2 regularization, with a dual formulation only for the L2 penalty.\n",
      " |  Elastic-Net penalty is only supported by the saga solver.\n",
      " |  \n",
      " |  For the grid of `Cs` values and `l1_ratios` values, the best hyperparameter\n",
      " |  is selected by the cross-validator\n",
      " |  :class:`~sklearn.model_selection.StratifiedKFold`, but it can be changed\n",
      " |  using the :term:`cv` parameter. The 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |  solvers can warm-start the coefficients (see :term:`Glossary<warm_start>`).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  Cs : list of floats or int, optional (default=10)\n",
      " |      Each of the values in Cs describes the inverse of regularization\n",
      " |      strength. If Cs is as an int, then a grid of Cs values are chosen\n",
      " |      in a logarithmic scale between 1e-4 and 1e4.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, optional (default=True)\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  cv : int or cross-validation generator, optional (default=None)\n",
      " |      The default cross-validation generator used is Stratified K-Folds.\n",
      " |      If an integer is provided, then it is the number of folds used.\n",
      " |      See the module :mod:`sklearn.model_selection` module for the\n",
      " |      list of possible cross-validation objects.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  dual : bool, optional (default=False)\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  penalty : str, 'l1', 'l2', or 'elasticnet', optional (default='l2')\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is\n",
      " |      only supported by the 'saga' solver.\n",
      " |  \n",
      " |  scoring : string, callable, or None, optional (default=None)\n",
      " |      A string (see model evaluation documentation) or\n",
      " |      a scorer callable object / function with signature\n",
      " |      ``scorer(estimator, X, y)``. For a list of scoring functions\n",
      " |      that can be used, look at :mod:`sklearn.metrics`. The\n",
      " |      default scoring option used is 'accuracy'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              optional (default='lbfgs')\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |      - 'liblinear' might be slower in LogisticRegressionCV because it does\n",
      " |        not handle warm-starting.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can preprocess the data\n",
      " |      with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-4)\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  max_iter : int, optional (default=100)\n",
      " |      Maximum number of iterations of the optimization algorithm.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         class_weight == 'balanced'\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used during the cross-validation loop.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      For the 'liblinear', 'sag' and 'lbfgs' solvers set verbose to any\n",
      " |      positive number for verbosity.\n",
      " |  \n",
      " |  refit : bool, optional (default=True)\n",
      " |      If set to True, the scores are averaged across all folds, and the\n",
      " |      coefs and the C that corresponds to the best score is taken, and a\n",
      " |      final refit is done using these parameters.\n",
      " |      Otherwise the coefs, intercepts and C that correspond to the\n",
      " |      best scores across folds are averaged.\n",
      " |  \n",
      " |  intercept_scaling : float, optional (default=1)\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  multi_class : {'ovr', 'multinomial', 'auto'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`. Used when `solver='sag'` or `solver='liblinear'`.\n",
      " |      Note that this only applies to the solver and not the cross-validation\n",
      " |      generator.\n",
      " |  \n",
      " |  l1_ratios : list of float or None, optional (default=None)\n",
      " |      The list of Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``.\n",
      " |      Only used if ``penalty='elasticnet'``. A value of 0 is equivalent to\n",
      " |      using ``penalty='l2'``, while 1 is equivalent to using\n",
      " |      ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a combination\n",
      " |      of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array, shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem\n",
      " |      is binary.\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape(1,) when the problem is binary.\n",
      " |  \n",
      " |  Cs_ : array, shape (n_cs)\n",
      " |      Array of C i.e. inverse of regularization parameter values used\n",
      " |      for cross-validation.\n",
      " |  \n",
      " |  l1_ratios_ : array, shape (n_l1_ratios)\n",
      " |      Array of l1_ratios used for cross-validation. If no l1_ratio is used\n",
      " |      (i.e. penalty is not 'elasticnet'), this is set to ``[None]``\n",
      " |  \n",
      " |  coefs_paths_ : array, shape (n_folds, n_cs, n_features) or                    (n_folds, n_cs, n_features + 1)\n",
      " |      dict with classes as the keys, and the path of coefficients obtained\n",
      " |      during cross-validating across each fold and then across each Cs\n",
      " |      after doing an OvR for the corresponding class as values.\n",
      " |      If the 'multi_class' option is set to 'multinomial', then\n",
      " |      the coefs_paths are the coefficients corresponding to each class.\n",
      " |      Each dict value has shape ``(n_folds, n_cs, n_features)`` or\n",
      " |      ``(n_folds, n_cs, n_features + 1)`` depending on whether the\n",
      " |      intercept is fit or not. If ``penalty='elasticnet'``, the shape is\n",
      " |      ``(n_folds, n_cs, n_l1_ratios_, n_features)`` or\n",
      " |      ``(n_folds, n_cs, n_l1_ratios_, n_features + 1)``.\n",
      " |  \n",
      " |  scores_ : dict\n",
      " |      dict with classes as the keys, and the values as the\n",
      " |      grid of scores obtained during cross-validating each fold, after doing\n",
      " |      an OvR for the corresponding class. If the 'multi_class' option\n",
      " |      given is 'multinomial' then the same scores are repeated across\n",
      " |      all classes, since this is the multinomial class. Each dict value\n",
      " |      has shape ``(n_folds, n_cs`` or ``(n_folds, n_cs, n_l1_ratios)`` if\n",
      " |      ``penalty='elasticnet'``.\n",
      " |  \n",
      " |  C_ : array, shape (n_classes,) or (n_classes - 1,)\n",
      " |      Array of C that maps to the best scores across every class. If refit is\n",
      " |      set to False, then for each class, the best C is the average of the\n",
      " |      C's that correspond to the best scores for each fold.\n",
      " |      `C_` is of shape(n_classes,) when the problem is binary.\n",
      " |  \n",
      " |  l1_ratio_ : array, shape (n_classes,) or (n_classes - 1,)\n",
      " |      Array of l1_ratio that maps to the best scores across every class. If\n",
      " |      refit is set to False, then for each class, the best l1_ratio is the\n",
      " |      average of the l1_ratio's that correspond to the best scores for each\n",
      " |      fold.  `l1_ratio_` is of shape(n_classes,) when the problem is binary.\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes, n_folds, n_cs) or (1, n_folds, n_cs)\n",
      " |      Actual number of iterations for all classes, folds and Cs.\n",
      " |      In the binary or multinomial cases, the first dimension is equal to 1.\n",
      " |      If ``penalty='elasticnet'``, the shape is ``(n_classes, n_folds,\n",
      " |      n_cs, n_l1_ratios)`` or ``(1, n_folds, n_cs, n_l1_ratios)``.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegressionCV\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]).shape\n",
      " |  (2, 3)\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.98...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  LogisticRegression\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegressionCV\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2', scoring=None, solver='lbfgs', tol=0.0001, max_iter=100, class_weight=None, n_jobs=None, verbose=0, refit=True, intercept_scaling=1.0, multi_class='auto', random_state=None, l1_ratios=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the score using the `scoring` option on the given\n",
      " |      test data and labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Score of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LogisticRegression:\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegressionCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg1.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[[-3.35104942e-02, -8.16025955e-04,  3.88575099e-03, ...,\n",
       "           2.36517757e-02, -1.20657159e-02, -1.90648470e+00],\n",
       "         [-2.11396114e-01,  6.45763820e-04,  4.51381316e-03, ...,\n",
       "           1.28866740e-01, -5.00846213e-02, -1.90187844e+00],\n",
       "         [-7.62134127e-01,  1.06536034e-01,  6.35200346e-03, ...,\n",
       "           3.41066032e-01, -1.79106390e-02, -2.07999058e+00],\n",
       "         ...,\n",
       "         [-2.15463127e+00,  2.23707034e+00,  9.28500911e-03, ...,\n",
       "           4.61595053e-01,  2.43081475e-02, -3.89539218e+00],\n",
       "         [-2.15463127e+00,  2.23707031e+00,  9.28535813e-03, ...,\n",
       "           4.61595074e-01,  2.43081134e-02, -3.89539218e+00],\n",
       "         [-2.15463129e+00,  2.23707018e+00,  9.28501061e-03, ...,\n",
       "           4.61595164e-01,  2.43079537e-02, -3.89539222e+00]],\n",
       " \n",
       "        [[-3.31484111e-02, -1.13788403e-03,  3.47916254e-03, ...,\n",
       "           2.28626293e-02, -1.11618985e-02, -1.82177113e+00],\n",
       "         [-2.10218379e-01, -1.25569240e-03,  4.12234600e-03, ...,\n",
       "           1.24324089e-01, -4.58078023e-02, -1.81852778e+00],\n",
       "         [-7.66067249e-01,  9.98383243e-02,  5.95034574e-03, ...,\n",
       "           3.24357020e-01, -1.38065757e-02, -1.97727078e+00],\n",
       "         ...,\n",
       "         [-2.13535195e+00,  2.23294603e+00,  8.69217978e-03, ...,\n",
       "           3.20227590e-01, -9.44714280e-02, -3.90969664e+00],\n",
       "         [-2.13535194e+00,  2.23294595e+00,  8.69279691e-03, ...,\n",
       "           3.20226930e-01, -9.44708858e-02, -3.90969737e+00],\n",
       "         [-2.10650876e+00,  2.23790834e+00,  8.73094440e-03, ...,\n",
       "           3.17283851e-01, -9.95895905e-02, -3.94965452e+00]],\n",
       " \n",
       "        [[-3.43579670e-02, -9.98979831e-04,  3.46796462e-03, ...,\n",
       "           2.20803680e-02, -1.09618346e-02, -1.82044504e+00],\n",
       "         [-2.19128664e-01, -6.61817838e-04,  3.91818385e-03, ...,\n",
       "           1.17738051e-01, -4.51632833e-02, -1.76664201e+00],\n",
       "         [-7.90239298e-01,  1.10333646e-01,  5.64605489e-03, ...,\n",
       "           2.98096602e-01, -1.63507238e-02, -1.88798233e+00],\n",
       "         ...,\n",
       "         [-2.23047901e+00,  2.46958092e+00,  7.76579001e-03, ...,\n",
       "           3.03417422e-01, -6.10603621e-02, -3.80701395e+00],\n",
       "         [-2.23047900e+00,  2.46958093e+00,  7.76566379e-03, ...,\n",
       "           3.03417411e-01, -6.10603524e-02, -3.80701395e+00],\n",
       "         [-2.23047898e+00,  2.46958097e+00,  7.76579006e-03, ...,\n",
       "           3.03417343e-01, -6.10602904e-02, -3.80701398e+00]],\n",
       " \n",
       "        [[-3.31627454e-02, -1.19540855e-03,  3.91447669e-03, ...,\n",
       "           2.25299313e-02, -1.13887092e-02, -1.91199554e+00],\n",
       "         [-2.10186088e-01, -1.79441774e-03,  4.56797569e-03, ...,\n",
       "           1.22242146e-01, -4.76014690e-02, -1.90771119e+00],\n",
       "         [-7.64344480e-01,  8.73013364e-02,  6.48756998e-03, ...,\n",
       "           3.14095159e-01, -2.53519429e-02, -2.06857233e+00],\n",
       "         ...,\n",
       "         [-2.21282467e+00,  2.03960942e+00,  1.01153463e-02, ...,\n",
       "           3.07856167e-01, -1.26762937e-01, -3.86390647e+00],\n",
       "         [-2.20395948e+00,  2.03632593e+00,  1.00628337e-02, ...,\n",
       "           2.98272449e-01, -1.14685528e-01, -3.85859323e+00],\n",
       "         [-2.20395945e+00,  2.03632591e+00,  1.00631068e-02, ...,\n",
       "           2.98272537e-01, -1.14685611e-01, -3.85859321e+00]],\n",
       " \n",
       "        [[-3.28532704e-02, -9.81742832e-04,  3.85306484e-03, ...,\n",
       "           2.38086828e-02, -1.19705033e-02, -1.89940778e+00],\n",
       "         [-2.09985727e-01, -1.81210663e-03,  4.25609296e-03, ...,\n",
       "           1.27819769e-01, -5.06769531e-02, -1.84161834e+00],\n",
       "         [-7.75232647e-01,  7.82986757e-02,  5.80938410e-03, ...,\n",
       "           3.26567955e-01, -2.88733787e-02, -1.90676142e+00],\n",
       "         ...,\n",
       "         [-2.14956915e+00,  1.69008528e+00,  8.25641707e-03, ...,\n",
       "           4.73298446e-01,  2.46186709e-02, -3.42208725e+00],\n",
       "         [-2.14956883e+00,  1.69008572e+00,  8.25585443e-03, ...,\n",
       "           4.73298804e-01,  2.46183539e-02, -3.42208727e+00],\n",
       "         [-2.14956877e+00,  1.69008580e+00,  8.25641316e-03, ...,\n",
       "           4.73298873e-01,  2.46182952e-02, -3.42208727e+00]]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.coefs_paths_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.1566089 ,  2.24358592,  0.00881543, -1.48014123, -1.20653764,\n",
       "         2.09096317, -3.10809112, -1.83605946, -1.11171145, -0.41466577,\n",
       "         3.21436987, -1.82956132,  0.83504739,  0.94611897,  2.80499459,\n",
       "         1.68754473, -1.99554576, -1.9110372 , -1.70275615, -0.26636163,\n",
       "        -0.60062644,  0.02461652,  0.27230442, -0.13261113, -0.09189228,\n",
       "        -0.3973424 , -0.07244507,  0.03874341,  0.06041983, -1.56458325,\n",
       "         0.40683446, -0.00744599]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.l1_ratios_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.75904762, 0.75904762, 0.84571429, 0.88333333, 0.89333333,\n",
       "         0.8952381 , 0.89428571, 0.89380952, 0.89380952, 0.89380952],\n",
       "        [0.75857143, 0.75857143, 0.84238095, 0.88142857, 0.88666667,\n",
       "         0.88761905, 0.88619048, 0.88714286, 0.88714286, 0.88761905],\n",
       "        [0.75857143, 0.75857143, 0.84      , 0.88238095, 0.88857143,\n",
       "         0.89      , 0.89      , 0.89      , 0.89      , 0.89      ],\n",
       "        [0.75857143, 0.75857143, 0.84761905, 0.88095238, 0.88238095,\n",
       "         0.88571429, 0.88428571, 0.8852381 , 0.8852381 , 0.8852381 ],\n",
       "        [0.75893283, 0.75893283, 0.85516913, 0.89375893, 0.89757027,\n",
       "         0.90090519, 0.89804669, 0.89804669, 0.89804669, 0.89804669]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933231736355843"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61116555e-01, 1.08151958e-01, 6.26126374e-04, ...,\n",
       "       1.89559381e-02, 2.42603600e-02, 1.30110854e-02])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg1.predict_proba(x_train)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992308690125632"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(lg1.predict_proba(x_train)[::,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2954859524672851e-05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(lg1.predict_proba(x_train)[::,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train[\"pred_prob\"]=lg1.predict_proba(x_train)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>number_project_2</th>\n",
       "      <th>number_project_3</th>\n",
       "      <th>number_project_4</th>\n",
       "      <th>number_project_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Departments_management</th>\n",
       "      <th>Departments_marketing</th>\n",
       "      <th>Departments_product_mng</th>\n",
       "      <th>Departments_sales</th>\n",
       "      <th>Departments_support</th>\n",
       "      <th>Departments_technical</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9236</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11503</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.74</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  average_montly_hours  \\\n",
       "10438                0.53             0.52                   135   \n",
       "9236                 0.77             0.53                   256   \n",
       "818                  0.89             0.79                   149   \n",
       "11503                0.64             0.63                   156   \n",
       "11721                0.98             0.74                   151   \n",
       "\n",
       "       Work_accident  left  promotion_last_5years  number_project_2  \\\n",
       "10438              0     0                      0                 1   \n",
       "9236               0     0                      0                 0   \n",
       "818                0     1                      0                 0   \n",
       "11503              1     0                      0                 0   \n",
       "11721              0     0                      0                 0   \n",
       "\n",
       "       number_project_3  number_project_4  number_project_5  ...  \\\n",
       "10438                 0                 0                 0  ...   \n",
       "9236                  0                 0                 1  ...   \n",
       "818                   1                 0                 0  ...   \n",
       "11503                 1                 0                 0  ...   \n",
       "11721                 0                 1                 0  ...   \n",
       "\n",
       "       Departments_management  Departments_marketing  Departments_product_mng  \\\n",
       "10438                       0                      0                        0   \n",
       "9236                        0                      0                        0   \n",
       "818                         0                      0                        0   \n",
       "11503                       0                      0                        0   \n",
       "11721                       0                      0                        0   \n",
       "\n",
       "       Departments_sales  Departments_support  Departments_technical  \\\n",
       "10438                  0                    0                      1   \n",
       "9236                   0                    0                      0   \n",
       "818                    0                    1                      0   \n",
       "11503                  0                    1                      0   \n",
       "11721                  1                    0                      0   \n",
       "\n",
       "       salary_high  salary_low  salary_medium  pred_prob  \n",
       "10438            0           0              1   0.661117  \n",
       "9236             0           0              1   0.108152  \n",
       "818              0           0              1   0.000626  \n",
       "11503            0           1              0   0.009174  \n",
       "11721            0           0              1   0.021072  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train[\"pred\"]=lg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>number_project_2</th>\n",
       "      <th>number_project_3</th>\n",
       "      <th>number_project_4</th>\n",
       "      <th>number_project_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Departments_marketing</th>\n",
       "      <th>Departments_product_mng</th>\n",
       "      <th>Departments_sales</th>\n",
       "      <th>Departments_support</th>\n",
       "      <th>Departments_technical</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9236</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11503</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.74</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  average_montly_hours  \\\n",
       "10438                0.53             0.52                   135   \n",
       "9236                 0.77             0.53                   256   \n",
       "818                  0.89             0.79                   149   \n",
       "11503                0.64             0.63                   156   \n",
       "11721                0.98             0.74                   151   \n",
       "\n",
       "       Work_accident  left  promotion_last_5years  number_project_2  \\\n",
       "10438              0     0                      0                 1   \n",
       "9236               0     0                      0                 0   \n",
       "818                0     1                      0                 0   \n",
       "11503              1     0                      0                 0   \n",
       "11721              0     0                      0                 0   \n",
       "\n",
       "       number_project_3  number_project_4  number_project_5  ...  \\\n",
       "10438                 0                 0                 0  ...   \n",
       "9236                  0                 0                 1  ...   \n",
       "818                   1                 0                 0  ...   \n",
       "11503                 1                 0                 0  ...   \n",
       "11721                 0                 1                 0  ...   \n",
       "\n",
       "       Departments_marketing  Departments_product_mng  Departments_sales  \\\n",
       "10438                      0                        0                  0   \n",
       "9236                       0                        0                  0   \n",
       "818                        0                        0                  0   \n",
       "11503                      0                        0                  0   \n",
       "11721                      0                        0                  1   \n",
       "\n",
       "       Departments_support  Departments_technical  salary_high  salary_low  \\\n",
       "10438                    0                      1            0           0   \n",
       "9236                     0                      0            0           0   \n",
       "818                      1                      0            0           0   \n",
       "11503                    1                      0            0           1   \n",
       "11721                    0                      0            0           0   \n",
       "\n",
       "       salary_medium  pred_prob  pred  \n",
       "10438              1   0.661117     1  \n",
       "9236               1   0.108152     0  \n",
       "818                1   0.000626     0  \n",
       "11503              0   0.009174     0  \n",
       "11721              1   0.021072     0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7943\n",
       "1    2556\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koti\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train[\"pred_flag\"]=np.where(train[\"pred_prob\"]>0.513,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7942\n",
       "1    2557\n",
       "Name: pred_flag, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"pred_flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_flag</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7886</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_flag     0     1\n",
       "pred                 \n",
       "0          7886    57\n",
       "1            56  2500"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train[\"pred\"],train[\"pred_flag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7363</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred     0     1\n",
       "left            \n",
       "0     7363   603\n",
       "1      580  1953"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train[\"left\"],train[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7363,  603],\n",
       "       [ 580, 1953]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train[\"left\"],train[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(train[\"left\"],train[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'predicted')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEJCAYAAAB8Pye7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcj0lEQVR4nO3deXwV1f3/8dcnCRASIGwJmyjigoqCKNAKCAhSFbRS3L9trahFrVpxQSq4oBVErVvrBi4IVq2KAqJoXVD4uVQ2FWVzZV8CJAQIiyb5/P64Q0hIWKK5E5J5Px+PPDJ37sw5Z8Llfc89M3OuuTsiIhItCRXdABERCZ/CX0QkghT+IiIRpPAXEYkghb+ISAQlVXQD9oUZuiRJRKSM3LHdPaeev4hIBFWKnv8Ol1GnopsgUmgUG4s99tycCmqJSHGWmrbXbdTzFxGJIIW/iEgEKfxFRCJI4S8iEkEKfxGRCFL4i4hEkMJfRCSCFP4iIhGk8BcRiSCFv4hIBCn8RUQiSOEvIhJBCn8RkQhS+IuIRJDCX0QkghT+IiIRpPAXEYkghb+ISAQp/EVEIkjhLyISQQp/EZEIUviLiESQwl9EJIIU/iIiEaTwFxGJIIW/iEgEKfxFRCJI4S8iEkEKfxGRCFL4i4hEkMJfRCSCFP4iIhGk8BcRiSCFv4hIBCn8RUQiSOEvIhJBCn8RkQhS+IuIRJDCX0QkghT+IiIRpPAXEYkghb+ISAQp/EVEIkjhLyISQQp/EZEIUviLiESQwl9EJIIU/iIiEZRU0Q2QvWt0+KFc+uIzhY8btmzB5FtHkNqgPm3P7I0XFLApcx1jL7qcnFWrATi8WxfOeXAkidWqsXndeu7v3pukGjW4YfpbJNWoTkJSEnPGT+L1YSNK1JdUvToXjRvFgce3I3d9Fk+edxHrlywF4JS/XUfnSy6kID+fl/56I/Pffi+Uv4FUHhs3beLm24fz9XffYWaMuO1mDm5xENcOHsqKlato1rQJD94zgrQ6dXj3/Wk89NgoEsxITExkyKDraN/u2BJlfjV/ATfddgfbtm+nW+dODL3xesyMDTk5pZYre2fuXtFt2CszHOAy9I9qCQmMXLGIu3/Vgy3ZG9i2aRMAJ119OU2OasXzV1xLzbQ0bvz4Hf55aj+yly2ndnpDNq1dB0CN1FS25+aSkJTEoA/f5qVrBvPDpzOL1dHtiktp1qY1z19xLe3PO4tjf3c6T57fnyZHtuKSF55mZMeTSGvahIHvvsath7fDCwpC/zvsD0axsdhjz82poJbsXwbfMoz27Y7lnH59+fGnn9i2bRuPPzWGunXSGHDxnxj99FhyNm1k0DVXk7tlCyk1a2JmLPz6GwYOHsJbE14uUebZf7iIoYOu49g2x/DnqwbyxwvOo1uXTtzz4D9LLTfqLDUNAHdsd9to2KeSOaJnd9Z99wNZS5cVBj9A9dQUdryRd/y/c/js1clkL1sOUBj8ANtzcwFIrFaNxGpJlPbm3+bMPnwy9gUA5oyfyBE9uxeun/mfV8j78UfWL15C5rff06Jj+7gcp1ROmzdvZuaczzj7d2cCUL1aNerUrs17H0yn7xl9AOh7Rh/efX8aAKkpKZjF8mnr1q2Fy0Vlrl3H5txc2rVtg5nR9/TevPdBbP/dlSt7F9qwj5m9AjwNvOnu0ewqloP255/FzBfGFz4+885b+NWFF7A1ZyMPnBT7T5Bx+KEkVqvGde+/QY3atZj60ON8+mwszC0hgSGzp5N+aEumPfIEi2fMKlFH3WZNCt84CvLz2ZqzkdQG9anXrCnf/2/np4QNy1dQr1kTfojnAUulsmzFSurXq8dNt93Bwq+/ofWRRzD0xutZvz6LjPSGAGSkNyQrK7twn3emvs99/3qUrKxsRv3z/hJlrsnMpHFGRuHjxo0yWJOZCbDHcmXPwuz5Pwb8H/CNmY00syP2tLGZDTCzWWY2C0aH08L9XGK1arT9bW9mvzyhcN2km//OkAOPYsZzL9H9qsti2yUlceDxx/Jwn3P45ym/o88tN5Jx2KEAeEEBw9t14aYDjqRFx+Np2vrIEvWU1vvCgVLWV4ZhQwlPXl4e8xcu4oJzzmLif/5NzZo1Gf302D3u06vHSbw14WUeuf8eHnp0VInnS3uFlfoalTIJLfzd/V13/z1wHLAYeMfMPjaz/mZWrZTtR7t7e3dvDwPCauZ+7ejTerF0zhdsylxb4rmZz79Mu7N+C0D28hXMf+tdftyyhdz1WXwz/SMOaHt0se235uTw9Qcf0vrUk0uUlb18JfWaHwBAQmIiNdPqkJuVRfbyFdRr3qxwu7oHNGPDytXleYhSyTVulEHjjAzaHhN7vZ16cg/mL1xEgwb1yQyGHzPXrqN+/Xol9u1w/HEsXb6crOwNxcvMyGB10NMHWL0mk4z0dIB9KldKF+qYv5k1AC4CLgU+Ax4i9mbwTpjtqKzaX3AOM1/YeTIs49BDCpfb/LY3axZ+DcAXk97g0BNPICExkWo1a9LiV+1ZvWARtRo2oGZa7ERQteRkjji5O6sXflOinrmvTeGEP10AwHFn92XR1GmF6zucfxZJ1avToMVBZBzWstRhI4mu9IYNadw4g+8XLwHgkxkzOaTlwfTo1pWJk98AYOLkN+jZvSsAS5YuK/z0OG/BQn76KY96ddOKlZmR3pDUlBQ+n/sl7s7E16fQs1ts/92VK3sX2tU+ZvYqcATwLPCMu68q8tysWA9/d/vqap9qNWty17IF3NyyDds2xq4yGTD+WRq1OgwvKCBryTKev3wgG1bG/qy9bvgrnfr/gYKCAj56chxTH3qUZse05k9jHychMRFLSGD2SxOY8ve7ATjj9qEsmTWHuZPfJKlGDfo/O5rm7dqyJSubJ8/vz7ofFgNw2pAb6HTxH8nPy+PlgX9j3lvRfd/W1T6lW7Doa4befic/5eXRvFlT7rr9VgoKChg4eAirVq2hSZNGPHTPXdRNS2P0mLFMen0KSUlJJNeowaBr/1p4qeeZ5/2eSS8+B8CX8+YXXurZtXMnbhl8A2ZG9oYNpZYbdftytU+Y4d/D3af+vH0V/rL/UfjL/mpfwj+0q33cfaqZHQ0cBSQXWT8urDaIiEhMmJd63gZ0Jxb+U4DTgA8Bhb+ISMjCPOF7NtATWO3u/YG2QI0Q6xcRkUCY4b81uLkrz8zqAJlAyxDrFxGRQJgTu80ys7rAE8BsYDMwI8T6RUQkEOYJ378Ei4+b2VtAHXefG1b9IiKyU2jDPmZWOPevuy9297lF14mISHji3vM3s2QgBWhoZvWg8LrTOkDTeNcvIiIlhTHscxkwkFjQzyYW/g5sAh4OoX4REdlF3Id93P0hdz8YGA4cGyyPAb4HPol3/SIiUlKo1/m7+0Yz6wL0Ap4hNs2ziIiELMzwzw9+9wEed/dJQPUQ6xcRkUCY4b/CzEYB5wJTzKxGyPWLiEggzPA9F/gvcKq7bwDqA4NCrF9ERAJh3uS1BXi1yONVwKrd7yEiIvGiYRcRkQhS+IuIRJDCX0QkghT+IiIRpPAXEYkghb+ISAQp/EVEIkjhLyISQQp/EZEIUviLiESQwl9EJIIU/iIiEaTwFxGJIIW/iEgEKfxFRCJI4S8iEkH7HP5mdp2ZHRss/9rMlprZ92Z2QvyaJyIi8VCWnv+1wA/B8l3A/cBw4MHybpSIiMRXWb7GMc3dc8ysNtAWONnd883svji1TURE4qQs4b/MzDoBrYHpQfDXAfLj0zQREYmXsoT/IGA88CNwVrDudGBGeTdKRETia5/D392nAE13Wf1y8CMiIpXIHsPfzFruYznfl0NbREQkJHvr+X8LOGB72MaBxHJrkYiIxN0ew9/ddROYiEgVpHAXEYmgfT7ha2ZJwF+AbkBDigwFuXvX8m+aiIjES1l6/g8AlwHTgeOBV4AMYGoc2iUiInFUlvDvB5zm7g8BecHvvsBJcWmZiIjETVnCPwVYFixvNbMUd18ItCv/ZomISDyV5Q7fBUAHYnf0zgKGmdlGYEU8GiYiIvFTlvC/hp3z+FwHPAbUBgaUd6NERCS+zN0rug17Zcb+30gRkf2M++5v0C3LpZ49dl+B64ofEZFKZJ97/mb2wy6r0oHqwHJ339c5gH4W9fxFRMquXHr+7n5w0cdmlgjcDGz6+U0TEZGK8IvG/IO7fpe7e+Pya1Jp9cR6/p6bE89qRMrEUtOKPc6fMaWCWiJSXGLH3sCee/6/dG6fXkDBLyxDRERCVpYTvsug2Nh7CpAMXFnejRIRkfgqy3X+f9jlcS7wtbtvLMf2iIhICMoS/h3c/R+7rjSz69z9/nJsk4iIxFlZxvxv3c36m8ujISIiEp699vyL3NyVaGYnUfwrHVuiSz1FRCqdfRn2eSr4nQw8XWS9A2uAq8u7USIiEl97Df8dN3eZ2Th3vzD+TRIRkXgry5j//WbWvOgKM2tuZm3LuU0iIhJnZQn/fwPVdllXHXi2/JojIiJhKEv4H+ju3xdd4e7fAS3KtUUiIhJ3ZQn/5WZ2XNEVweOV5dskERGJt7Lc5PUAMMnM7gG+Aw4BbgCGx6NhIiISP2WZ0vkJM9sAXAI0B5YC17v7+Hg1TkRE4qMsPX+A6cB2oGHwuI6ZXezuT+9hHxER2c+UZVbPvsSu7PkWaA3MA44GPqT4zV8iIrKfK8sJ3zuBi929HZAb/B4AzI5Ly0REJG7Keqnny7usGwvorl8RkUqmLOGfaWaNguXFZnYCsSt+Esu/WSIiEk9lCf8ngC7B8gPA+8AXwKPl3SgREYmvslzqeXeR5XFm9gGQ6u4L4tEwERGJn7Je6lnI3ZeWZ0NERCQ8ZRn2ERGRKkLhLyISQQp/EZEIUviLiESQwl9EJIIU/iIiEaTwFxGJIIW/iEgEKfxFRCJI4S8iEkEKfxGRCFL4i4hEkMJfRCSCFP4iIhGk8BcRiSCFv4hIBCn8RUQiSOEvIhJBCn8RkQhS+IuIRJDCX0QkghT+IiIRpPAXEYkghb+ISAQp/EVEIiipohsgZdej95mkpqaQkJBAYmIirz4/jgWLvua24SPZvn07iYmJDBsymDZHt8bdGX7PfUz76GOSk5MZefuttD7yiBJlfjV/ATfddgfbtm+nW+dODL3xesyMDTk5XDt4KCtWrqJZ0yY8eM8I0urUqYCjlv3V0NEv8MHn86lfpxaTRw4GYOGSFQwb8zJbtv1Is/R63HvFH6mVksyKtVn0uXEkBzdJB6DtoQcx7OJzAfjz3aNYm7ORvPx82rdqyS0XnU1iQvH+qbsz4tkJTP98Ack1qjFiwAW0Prg5ABOnz+CxSe8AcMWZvejbtWNYf4JKST3/Smrs6MeY9OJzvPr8OADuffBfXDngUia9+BzXXHEZ9z74LwCmf/gxi5cu4+1Jr/D3m29i2Ii7Sy1v2Ii7uePmm3h70issXrqM6R99AsDoMWM5oWMH3n7tFU7o2IHRY8aGc4BSafTt2pHRgwYUW3fLky9y3Xmn89rIGzm5fRueemNq4XPNGzVgwohBTBgxqDD4AR64+k9MHDGIySMHk7Upl7c+/bxEXdO/WMCS1Wt5674h3H7JudzxzHgANmzO5ZEJ/+XF2wfy0h3X8siE/5KTuyVOR1w1KPyrCDPIzc0FYNPmzWSkNwTgvWnT6Xt6b8yMY9scw8ZNm8hcu67Yvplr17E5N5d2bdtgZvQ9vTfvfTAttv8H0+l7Rh8A+p7Rh3ffnxbiUUll0OGIQ6hbK7XYuh9WZdLhiEMA6HT04bwzc+5ey6mVkgxAXn4BP+XlYWYltpk6+yvO7NIh9no+tAUbc7eSmZ3DR3MX0enoVtStlUpaagqdjm7Fh18sLIejq7o07FMZGVzyl6sxM84763ecd9bvGHLDdVxy5V+5+4GHKChw/vPMkwCsycykceNGhbs2bpTBmszMwjeHwm0yMkpsA7B+fVbhthnpDcnKyg7jCKWSO6x5E6bO+Yqexx/Dfz/9glVZGwqfW7E2i35D/0FqzWSuOfs02gdvEgCX3v04X363lBPbHskpHduWKHdNdg6NG9QtfNy4fl0ys3NKrG9Uvy5rsnPidHRVQ2jhb2adgWHAQUG9Bri7t9zN9gOA4LPkqJ2LwgtjnqRRRjrrs7Lof/lVtGxxEP99dyo3XX8tp5zcgylvv8PQ2+/kmVGP4F5y/117VKVsUmqvS2RfDf/z+Qwf9yqPTnibHse1plpSIgDpdevw3oO3Uq92KvN+WMZVDzzN5JGDC3v9Tw6+nO0//sSgx/7N/+Z9Q+djWhUr10t5QZvZbtbH4cCqkDCHfZ4C7ge6AB2A9sHvUrn7aHdv7+7tFfzFNcqInSxrUL8+vXp0Z+68+Ux4/Q1+0/MkAE7rdTJz580HYr341avXFO67ek0mGenpxcprnJHB6qCnv+s2DRrULxwmyly7jvr168XtuKTqaNm0EU/97QpeufN6ep9wHAdmxD49Vq+WRL3asSGi1gc3p3lGAxavziy2b43q1ejRrjVT53xVotzG9euyev3OTxGrszaQXrdOifVrsjaQUTctHodWZYQZ/jnu/qa7Z7r7+h0/IdZfJWzZupXNwdj+lq1b+eiTTznskEPISE9nxuw5APxvxkxaHBi7AqJHtxOZ+PoU3J3P535J7Vq1ig35QGw4JzUlhc/nfom7M/H1KfTs1jXYvysTJ78BwMTJb9Cze9ewDlUqsfU5mwAoKCjg8UnvcF7PTgBkbdxMfkEBAMsy17FkzToOyGhA7rbtZAbDNHn5+Uz7YgEtm2SUKPek41oz6cOZsdfzt4upnVKTjHppdG7Tio++WkRO7hZycrfw0VeL6NymVYn9Zacwx/zfN7N7gVeB7TtWuvucENtQ6a1fn8WV1w0CID8/n9NPO4WunU8gJaUmI+69n7y8PGrUqMEdN98EQLcunZn24cf0+m0/aiYnM2LYLYVlnXne75n04nMADBsyuPBSz66dO9G1S+w/64D+FzJw8BDGT3yNJk0a8dA9d4V8xLK/u/7hccxY8C0bNufS/ephXHXWqWzZtp3n3/0IgF7tj6FfcNnlrIXf8c9X3iQpMZEEM4b1P5u6tVJZl7OJK+9/ih/z8sgvKODXRx1W+Ibxn/di5ZzfszPdjj2K6V8s4JTrh5NcvTojBpwPQN1aqVzR9zece8sDAPyl729KnISW4qy0sbK4VGT2fimr3d177H3f2LC05+oEjuw/LLX4sEL+jCkV1BKR4hI79gbAnd2e+Qil529mCcBj7v5SGPWJiMiehTLm7+4FwFVh1CUiInsX5gnfd8zsBjNrbmb1d/yEWL+IiATCPOF7cfD7yiLrHCj1On8REYmf0MLf3Q8Oqy4REdmzMO/wvbC09e4+Lqw2iIhITJjDPkXv5k0GegJzAIW/iEjIwhz2ubroYzNLA54Nq34REdmpIqd03gIcVoH1i4hEVphj/pPZOYFkAnAUoJu+REQqQJhj/v8ospwHLHH35SHWLyIigTDH/PUVUCIi+4nQxvzNrJ+ZfWNmOWa20cw2mdnGsOoXEZGdwhz2uQc4w90XhFiniIiUIsyrfdYo+EVE9g9x7/mbWb9gcZaZvQhMpPiXubwa7zaIiEhxYQz7nBH8dmLX9v+myHNO7Ju9REQkRHEPf3fvD2BmY4Fr3H1D8LgecF+86xcRkZLCHPNvsyP4Adw9G2gXYv0iIhIIM/wTgt4+AMEXuYR5tZGIiATCDN/7gI/NbDyxsf5zgeEh1i8iIoEw7/AdZ2azgB6AAf3cfX5Y9YuIyE6hDrsEYa/AFxGpYBU5pbOIiFQQhb+ISAQp/EVEIkjhLyISQQp/EZEIUviLiESQwl9EJIIU/iIiEaTwFxGJIIW/iEgEKfxFRCJI4S8iEkEKfxGRCFL4i4hEkMJfRCSCFP4iIhGk8BcRiSCFv4hIBCn8RUQiSOEvIhJBCn8RkQhS+IuIRJDCX0QkghT+IiIRpPAXEYkgc/eKbsNembH/N1JEZD/jju3uOfX8RUQiqFL0/KV8mdkAdx9d0e0Q2ZVem+FRzz+aBlR0A0R2Q6/NkCj8RUQiSOEvIhJBCv9o0piq7K/02gyJTviKiESQev4iIhGk8BcRiSCFfxVnZgPNLKWi2yFiZs+Y2dkV3Q6JUfhXfQMBhb9UemaWWNFtqEoU/lWImaWa2Rtm9oWZfWVmtwFNgffN7P1gm8fMbJaZzTOz24N1Pc1sQpFyepnZqxVzFFJVmNmFZjY3eD0+G6zuamYfm9n3Oz4FmFl3M3u9yH4Pm9lFwfJiM7vVzD4EzjGzD8zsbjObYWZfm9mJoR9YFZFU0Q2QcnUqsNLd+wCYWRrQHzjJ3dcF2wx196ygF/WembUBpgKPmFm6u68N9hlTAe2XKsLMWgNDgc7uvs7M6gP3A02ALsARwGvA+H0obpu7dwnKvRxIcveOZtYbuA04OR7HUNWp51+1fAmcHPSMTnT3nFK2OdfM5gCfAa2Bozx2ve+zwB/MrC5wAvBmaK2WqqgHMH5Hp8Pds4L1E929wN3nA432sawXd3m841PpbKDFL21oVKnnX4W4+9dmdjzQG7jLzN4u+ryZHQzcAHRw92wzewZIDp4eA0wGtgEvu3teeC2XKsig1KnYt++yDUAexTuiyRSXu5sy8lGG/Wzq+VchZtYU2OLu/wb+ARwHbAJqB5vUIfYfKcfMGgGn7djX3VcCK4GbgWdCbLZUTe8R+5TZACAY9tmdJcBRZlYjGKrsGUYDo07vmlXLMcC9ZlYA/ARcQTCEY2ar3P0kM/sMmAd8D3y0y/7PAenBR3KRn83d55nZcGCameUTG2bc3bbLzOwlYC7wzZ62lfKj6R2kkJk9DHzm7k9VdFtEJL4U/gKAmc0mNiTUy9237217EancFP4iIhGkE74iIhGk8BcRiSCFv4hIBCn8RcogmJnyzmD5RDNbFFK9bmaHhlGXRIPCX+Rncvf/5+6t9radmV0UTEwmst9Q+EtkmZlucpTIUvhLlRNMA3yTmc03s2wzG2NmycHUwcvNbLCZrSaYudTMTjezz81sQzDdcJsiZbUzszlmtsnMXqTIvDM7yivyuLmZvWpma81sfTA18ZHA48AJZrbZzDYE29Yws3+Y2VIzW2Nmj5tZzSJlDTKzVWa20swujv9fTaJG4S9V1e+BU4BDgMOJzVkE0BioDxwEDDCz44CngcuABsAo4LUgnKsDE4nNeFofeBk4q7TKgimyXyc2T00LoBnwH3dfAFwOfOLutdy9brDL3UG7jgUODba/NSjrVGIT8PUCDkNTFkscKPylqnrY3ZcFUwkPBy4I1hcAt7n7dnffCvwZGOXun7p7vruPJTZr5K+Dn2rAg+7+k7uPB2bupr6OxL44Z5C757r7NncvdZzfzCyo91p3z3L3TcAI4Pxgk3OBMe7+lbvnAsN+0V9CpBQa85SqalmR5SXEghlgrbtvK/LcQcCfzOzqIuuqB9s7sMKL3wa/ZDf1NQeW7ONU2OnEvlpzdux9AIhNb7zjawqbEpurfm91ivxs6vlLVdW8yPKBxKarhpJzzC8Dhrt73SI/Ke7+ArAKaGZFEjooqzTLgAN3cxJ51zrXAVuB1kXqTHP3WsHzq0ppv0i5UvhLVXWlmR0QzCM/hJLfBrXDE8DlZvYri0k1sz5mVhv4hNgXjfzVzJLMrB+x4Z3SzCAW2iODMpLNrHPw3BrggOAcAu5eENT7gJllAJhZMzM7Jdj+JeAiMzvKzFKIfVWhSLlS+EtV9TzwNrHvLfgeuLO0jdx9FrHx94eBbOBb4KLguR+BfsHjbOA8dn6F4K7l5ANnEDt5uxRYHmwPse9IngesNrMd36U8OKjrf2a2EXgXaBWU9SbwYLDft8FvkXKlWT2lyjGzxcCl7v5uRbdFZH+lnr+ISAQp/EVEIkjDPiIiEaSev4hIBCn8RUQiSOEvIhJBCn8RkQhS+IuIRND/BzwoksgOCvi1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True,fmt='.2f',cmap=\"Reds\",linecolor=\"b\",linewidths=3,cbar=False,xticklabels=[\"stay\",\"churn\"]\n",
    "            ,yticklabels=[\"stay\",\"churn\"])\n",
    "plt.ylabel(\"actuals\",fontsize=12)\n",
    "plt.xlabel(\"predicted\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887322602152586"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7363+1953)/(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887322602152586"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train[\"left\"],train[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11267739784741404"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "brier_score_loss(train[\"left\"],train[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
